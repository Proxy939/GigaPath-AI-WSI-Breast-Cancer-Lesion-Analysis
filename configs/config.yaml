# GigaPath AI WSI Breast Cancer Lesion Analysis - Configuration
# Optimized for RTX 4070 8GB GPU

# ============================================================================
# Experiment Configuration - Reproducibility
# ============================================================================
experiment:
  seed: 42                    # Random seed for reproducibility
  deterministic: true         # Enable deterministic algorithms
  project_name: "GigaPath-WSI-Breast-Cancer"
  run_name: "baseline"        # Experiment run identifier

# ============================================================================
# Stage 0: WSI Preprocessing
# ============================================================================
preprocessing:
  tile_size: 256              # Tile size in pixels (256×256)
  magnification: 20           # Target magnification level (20×)
  overlap: 0                  # Tile overlap in pixels (0 = no overlap)
  tissue_threshold: 0.5       # Minimum tissue ratio to keep tile (0.0-1.0)
  gray_threshold: 200         # Grayscale threshold for background detection
  thumbnail_size: 2000        # Thumbnail size for tissue detection
  save_format: "png"          # png or jpg (for debug mode only)
  jpeg_quality: 95            # If using jpg in debug mode
  formats:                    # Supported WSI formats
    - ".svs"
    - ".tiff"
    - ".ndpi"
    - ".mrxs"

# ============================================================================
# Stage 1: Feature Extraction
# ============================================================================
feature_extraction:
  backbone: "resnet50-imagenet" # Options: resnet50-imagenet, resnet50-simclr, ctranspath
  pretrained: true              # Use pretrained weights
  frozen: true                  # Freeze backbone weights (no fine-tuning)
  batch_size: 48                # Batch size for feature extraction (GPU-safe for RTX 4070)
  num_workers: 4                # DataLoader workers
  feature_dim: 2048             # Output feature dimension (ResNet50)
  cache_format: "h5"            # HDF5 format for feature caching
  normalize_features: false     # L2 normalization of features (optional)

# ============================================================================
# Stage 2: Top-K Tile Sampling
# ============================================================================
sampling:
  k: 1000                     # Number of top tiles to select
  ranking_method: "feature_norm"  # Options: feature_norm, attention (Phase 3)
  hybrid_weight: 0.7          # Weight for attention if using hybrid (Phase 3)

# ============================================================================
# Stage 3: MIL Aggregation & Classification
# ============================================================================
mil:
  # Model architecture
  input_dim: 2048             # Feature dimension from backbone
  hidden_dim: 512             # Hidden layer dimension
  attn_dim: 256               # Attention dimension
  num_classes: 2              # Binary classification
  dropout: 0.25               # Dropout probability
  
  # Training
  optimizer: "adam"           # Optimizer (adam, sgd)
  learning_rate: 0.0001       # Initial learning rate
  weight_decay: 0.00001       # L2 regularization
  batch_size: 1               # MIL batch size (always 1)
  num_epochs: 50              # Maximum epochs
  early_stopping_patience: 10 # Early stopping patience
  
  # Loss
  loss: "bce"                 # Binary cross-entropy with logits
  class_weight: null          # Optional class weight for imbalance
  
  # Learning rate schedule
  scheduler: "reduce_on_plateau"  # reduce_on_plateau, step, cosine
  scheduler_patience: 5       # Patience for ReduceLROnPlateau
  scheduler_factor: 0.5       # LR reduction factor
    
  # Validation parameters
  validation:
    split_ratio: 0.2          # Train/val split
    stratified: true          # Stratified split by class

# ============================================================================
# Stage 4: Explainability
# ============================================================================
explainability:
  generate_heatmaps: true     # Generate attention heatmaps
  heatmap_resolution: 256     # Heatmap resolution (downsampled from original)
  colormap: "jet"             # Options: jet, hot, viridis
  overlay_alpha: 0.5          # Transparency for WSI overlay (0.0-1.0)
  save_top_predictions: 10    # Save top N attention tiles

# ============================================================================
# GPU & Performance
# ============================================================================
hardware:
  gpu_id: 0                   # GPU device ID (-1 for CPU)
  max_vram_gb: 7.5            # Maximum VRAM usage (GB) - safety margin for 8GB
  mixed_precision: true       # Enable AMP (Automatic Mixed Precision)
  cudnn_benchmark: false      # Disable for deterministic behavior

# ============================================================================
# Paths
# ============================================================================
paths:
  data_root: "data"
  raw_wsi: "data/raw_wsi"
  processed_tiles: "data/processed"
  features: "data/features"
  models: "data/models"
  results: "data/results"
  logs: "logs"

# ============================================================================
# Logging
# ============================================================================
logging:
  level: "INFO"               # Options: DEBUG, INFO, WARNING, ERROR
  save_logs: true             # Save logs to file
  tensorboard: true           # Enable TensorBoard logging
  log_interval: 10            # Log every N batches
