# ðŸŽ¯ GigaPath AI WSI Breast Cancer Lesion Analysis

**Deep Learning Pipeline for Whole Slide Image Classification with Top-K Sampling**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ðŸ“‹ Overview

This project implements a state-of-the-art **Multiple Instance Learning (MIL)** pipeline for automated breast cancer classification from Whole Slide Images (WSI). The system leverages **Top-K tile sampling** to reduce computational overhead while maintaining high accuracy, making it suitable for resource-constrained environments (RTX 4070 8GB GPU).

### ðŸŽ“ Academic Context

This implementation follows modern WSI analysis methodologies (CLAM-style pipelines) and incorporates best practices from digital pathology research. The architecture is designed for:
- **Reproducible experiments** with deterministic behavior
- **Efficient GPU utilization** with smart memory management
- **Explainable AI** through attention-based heatmaps
- **Academic rigor** suitable for research papers and thesis work

---

## ðŸ—ï¸ Architecture

The pipeline consists of **5 distinct stages**:

```mermaid
graph TD
    A[Stage 0: WSI Preprocessing] -->|256Ã—256 tiles| B[Stage 1: Feature Extraction]
    B -->|Frozen Backbone| C[Stage 2: Top-K Sampling]
    C -->|K=1000 tiles| D[Stage 3: MIL Aggregation]
    D -->|Classification| E[Stage 4: Explainability]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#e1ffe1
    style E fill:#f5e1ff
```

### Stage Breakdown

| Stage | Description | Key Technology | Output |
|-------|-------------|----------------|--------|
| **0: Preprocessing** | Tissue detection & tiling | OpenSlide, OpenCV | 256Ã—256 tiles + coordinates |
| **1: Feature Extraction** | Frozen SSL backbone | ResNet50/CTransPath | 2048-dim embeddings (cached) |
| **2: Top-K Sampling** | Attention-based ranking | Feature norm / Attention | K=1000 most informative tiles |
| **3: MIL Aggregation** | Slide-level classification | Attention MIL / Gated MIL | Benign/Malignant prediction |
| **4: Explainability** | Attention heatmaps | Attention weights | WSI overlay visualization |

---

## ðŸŽ¯ Key Features

### âœ… Top-K Tile Sampling
- **Problem**: WSI contains 10kâ€“100k tiles, most are background/uninformative
- **Solution**: Rank tiles by attention scores, select top K=1000
- **Benefit**: 10Ã— faster training, sharper heatmaps, stable MIL learning

### âœ… GPU-Safe Design
- Optimized for **RTX 4070 8GB** with VRAM monitoring
- Automatic batch size adjustment
- Mixed precision training (AMP)
- Feature caching to avoid recomputation

### âœ… Full Reproducibility
```yaml
experiment:
  seed: 42
  deterministic: true
```
- Fixed random seeds across NumPy, PyTorch, Python
- Deterministic algorithms enabled
- Same results across multiple runs

### âœ… Explainability
- Attention-based heatmaps showing critical regions
- Tile-level importance scores
- WSI overlay visualization

---

## ðŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/yourusername/GigaPath-AI-WSI-Breast-Cancer-Lesion-Analysis.git
cd GigaPath-AI-WSI-Breast-Cancer-Lesion-Analysis

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package
pip install -e .
```

### 2. Verify Installation

```bash
# Check Python version
python --version  # Should be 3.8+

# Check PyTorch GPU support
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"

# Check OpenSlide
python -c "import openslide; print(f'OpenSlide OK')"
```

### 3. Configuration

Edit `configs/config.yaml` to set:
- Data paths (`paths.raw_wsi`)
- GPU settings (`hardware.gpu_id`)
- Model parameters (`mil.architecture`)
- Top-K value (`sampling.k`)

### 4. Run Pipeline

```bash
# Stage 0: Preprocess WSI
python scripts/preprocess.py --config configs/config.yaml

# Stage 1: Extract features
python scripts/extract_features.py --config configs/config.yaml

# Stage 2: Sample top-K tiles
python scripts/sample_tiles.py --config configs/config.yaml

# Stage 3: Train MIL classifier
python scripts/train_mil.py --config configs/config.yaml

# Stage 4: Generate heatmaps
python scripts/generate_heatmaps.py --config configs/config.yaml
```

---

## ðŸ“ Project Structure

```
GigaPath-AI-WSI-Breast-Cancer-Lesion-Analysis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/          # Stage 0: Tissue detection & tiling
â”‚   â”œâ”€â”€ feature_extraction/     # Stage 1: Frozen backbone features
â”‚   â”œâ”€â”€ sampling/               # Stage 2: Top-K tile selection
â”‚   â”œâ”€â”€ mil/                    # Stage 3: MIL models
â”‚   â”œâ”€â”€ explainability/         # Stage 4: Heatmap generation
â”‚   â””â”€â”€ utils/                  # Shared utilities
â”‚       â”œâ”€â”€ logger.py           # Logging system
â”‚       â”œâ”€â”€ seed.py             # Reproducibility
â”‚       â”œâ”€â”€ gpu_monitor.py      # VRAM tracking
â”‚       â””â”€â”€ config.py           # Config loading
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # Pipeline configuration
â”œâ”€â”€ scripts/                    # CLI entry points
â”œâ”€â”€ tests/                      # Unit & integration tests
â”œâ”€â”€ data/                       # Data directory (gitignored)
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## ðŸ’» Hardware Requirements

### Minimum
- **GPU**: NVIDIA RTX 4070 8GB (or equivalent)
- **RAM**: 16 GB
- **Storage**: 100 GB (for WSI data + features)
- **OS**: Windows 10/11, Linux (Ubuntu 20.04+)

### Recommended
- **GPU**: RTX 4080 16GB or higher
- **RAM**: 32 GB
- **Storage**: 500 GB SSD

---

## ðŸ§  Academic Usage

### For Reports/Papers

You can describe this system as:

> *"We implement a Top-K tile sampling strategy prior to MIL aggregation, retaining only the K=1000 most informative tiles ranked by attention scores. This reduces computational overhead by ~10Ã— while suppressing irrelevant background regions, enabling stable MIL training and sharper explainability heatmaps."*

### Key Citations

This architecture is inspired by:
- **CLAM** (Lu et al., 2021): Data-efficient and weakly supervised computational pathology
- **Attention MIL** (Ilse et al., 2018): Deep multiple instance learning
- **Top-K Sampling**: Modern WSI analysis best practices

---

## ðŸ“Š Expected Results

| Metric | Value |
|--------|-------|
| **Preprocessing** | ~500-1000 tiles/WSI (after filtering) |
| **Feature Extraction** | ~10-15 slides/hour (RTX 4070) |
| **Top-K Selection** | K=1000 tiles retained |
| **Training Time** | ~2-3 hours/epoch (dataset-dependent) |
| **VRAM Usage** | <7.5 GB (safe margin) |
| **Reproducibility** | 100% (deterministic mode) |

---

## ðŸ› ï¸ Development

### Run Tests

```bash
pytest tests/
```

### Code Style

```bash
# Format code
black src/

# Lint code
flake8 src/
```

---

## ðŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ðŸ‘¥ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ðŸ“§ Contact

For questions or collaboration:
- **Author**: Aaradhy Patil
- **Email**: 
- **GitHub**: [@yourusername](https://github.com/yourusername)

---

## ðŸ™ Acknowledgments

- OpenSlide library for WSI handling
- PyTorch team for deep learning framework
- Digital pathology research community

---

**Built with â¤ï¸ for advancing AI in digital pathology**
